# -*- coding: utf-8 -*-
"""Fetal Health - Classificação

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R5C7Q0o-iXCW3X183WV_i5Q_2t2Fh1Ab

# Pré-Processamento
"""

import numpy as np
import pandas as pd

dados = pd.read_csv("/content/fetal_health.csv",sep=',')

dados.head()

# Análise das variáveis

dados.info()

# Remover duplicatas
dados = dados.drop_duplicates()
dados.info()

# renomear colunas 
dados = dados.rename(columns = {'baseline value':'baseline_value', 'prolongued_decelerations': 'prolonged_decelerations'})
dados.columns

dados.shape

# Análise dos tipos de atributos

dados.dtypes

dados.isnull().sum()

dados.describe()

import plotly.express as px

px.box(dados,y='baseline_value')

# Salvando (Exportando) o DF tratado

dados.to_csv('fetal_health_tratato.csv',sep=';', encoding='utf-8',index = False)

df = pd.read_csv('/content/fetal_health_tratato.csv', sep=';', encoding='utf-8')

df.head()

df.dtypes

previsores = df.iloc[:,0:21].values

previsores

previsores.shape

alvo = df.iloc[:,21].values

alvo

alvo.shape

## **Análise das escalas dos atributos (Escalonamento)**
df.describe()

# Utilizará a padronização

from sklearn.preprocessing import StandardScaler

previsores_esc = StandardScaler().fit_transform(previsores)

previsores_esc

previsoresdf = pd.DataFrame(previsores_esc)
previsoresdf

previsoresdf.describe()

#previsores_esc

# BASE DE TREINO E TESTE

from sklearn.model_selection import train_test_split

x_treino, x_teste, y_treino, y_teste = train_test_split(previsores_esc, alvo, test_size = 0.3, random_state = 0)

x_treino.shape

x_teste.shape

y_treino.shape

y_teste.shape

"""# Naive Bayes"""

# NAIVE BAYES

# Treinamento do algoritmo

from sklearn.naive_bayes import GaussianNB

naive = GaussianNB()
naive.fit(x_treino, y_treino)

# Avaliação do algoritmo

previsoes_naive = naive.predict(x_teste)
previsoes_naive

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

accuracy_score(y_teste, previsoes_naive)

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_naive) * 100.0))

confusion_matrix(y_teste, previsoes_naive)

print(classification_report(y_teste, previsoes_naive))

# Análise dados de Treino
previsoes_treino = naive.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# Validação Cruzada
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = GaussianNB()
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)
resultado

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

# SVM (Support Vector Machine)
"""

# SVM (Support Vector Machine)

from sklearn.svm import SVC

svm = SVC(kernel='rbf', random_state=1, C = 2) 
svm.fit(x_treino, y_treino)

previsoes_svm = svm.predict(x_teste)
previsoes_svm

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_svm) * 100.0))

confusion_matrix(y_teste, previsoes_svm)

print(classification_report(y_teste, previsoes_svm))

# Análise dados de treino
previsoes_treino = svm.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# VALIDAÇÃO CRUZADA

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = SVC(kernel='rbf', random_state=1, C = 2) 
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 92,11% - 584 acertos e 92,09% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

# Regressão Logística
"""

# **REGRESSÃO** LOGÍSTICA

from sklearn.linear_model import LogisticRegression

logistica = LogisticRegression(random_state=1, max_iter=600, penalty="l2",
                               tol=0.0001, C=1,solver="lbfgs")
logistica.fit(x_treino, y_treino)

logistica.intercept_

logistica.coef_

previsoes_logistica = logistica.predict(x_teste)
previsoes_logistica

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_logistica) * 100.0))

confusion_matrix(y_teste, previsoes_logistica)

print(classification_report(y_teste, previsoes_logistica))

# ANÁLISE DE DADOS DE TREINO
previsoes_treino = logistica.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# VALIDAÇÃO CRUZADA
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = LogisticRegression(random_state=1, max_iter=600, penalty="l2",
                               tol=0.0001, C=1,solver="lbfgs")
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 92,11% - 584 acertos e 92,09% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores3_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

# KNN
"""

# **APRENDIZAGEM BASEADA EM INSTÂNCIAS (KNN)**

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=1)
knn.fit(x_treino, y_treino)

previsoes_knn = knn.predict(x_teste)
previsoes_knn

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_knn) * 100.0))

confusion_matrix(y_teste, previsoes_knn)

print(classification_report(y_teste, previsoes_knn))

previsoes_treino = knn.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# VALIDAÇÃO CRUZADA

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 86,23% - 238 acertos e 85,72% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores3_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

KNN = 92,59% - 587 acertos e 90,82% (validação cruzada) :  previsores_esc - KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

# Árvore de Decisão
"""

# ARVORE DE DECISÃO

from sklearn.tree import DecisionTreeClassifier

arvore = DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)
arvore.fit(x_treino, y_treino)

previsoes_arvore = arvore.predict(x_teste)
previsoes_arvore

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_arvore) * 100.0))

confusion_matrix(y_teste, previsoes_arvore)

print(classification_report(y_teste, previsoes_arvore))

#**Análise dados de treino**
previsoes_treino = arvore.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# Validação Cruzada

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 86,23% - 238 acertos e 85,72% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

KNN = 92,59% - 587 acertos e 90,82% (validação cruzada) :  previsores_esc - KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

Árvore de decisão = 91,80% (treino e teste) - 582 acertos e 90,21% (validação cruzada): previsores_esc - DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

# Random Forest
"""

# **RANDOM FOREST**

from sklearn.ensemble import RandomForestClassifier

random = RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)
random.fit(x_treino, y_treino)

previsoes_random = random.predict(x_teste)
previsoes_random

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_random) * 100.0))

confusion_matrix(y_teste, previsoes_random)

print(classification_report(y_teste, previsoes_random))

# Análise dados de treino
previsoes_treino = random.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# Validação Cruzada
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 86,23% - 238 acertos e 85,72% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

KNN = 92,59% - 587 acertos e 90,82% (validação cruzada) :  previsores_esc - KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

Árvore de decisão = 91,80% (treino e teste) - 582 acertos e 90,21% (validação cruzada): previsores_esc - DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

Random Forest = 93,06% - 590 acertos e 90,82% (validação cruzada) : previsores - RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)

# XGBOOST
"""

# **XGBOOST**

from xgboost import XGBClassifier

xg = XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)
xg.fit(x_treino,y_treino)

previsoes_xg = xg.predict(x_teste)
previsoes_xg

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_xg) * 100.0))

confusion_matrix(y_teste, previsoes_xg)

print(classification_report(y_teste, previsoes_xg))

# **Análise dados de treino**

previsoes_treino = xg.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

### **Validação Cruzada**

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 86,23% - 238 acertos e 85,72% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

KNN = 92,59% - 587 acertos e 90,82% (validação cruzada) :  previsores_esc - KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

Árvore de decisão = 91,80% (treino e teste) - 582 acertos e 90,21% (validação cruzada): previsores_esc - DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

Random Forest = 93,06% - 590 acertos e 90,82% (validação cruzada) : previsores - RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)

XGboost = 95,27% - 604 acertos e 94,75% (validação cruzada) : previsores - XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)

# LIGHTGBM
"""

# **LIGHTGBM**

# Instalação do Algoritmo
!pip install lightgbm

import lightgbm as lgb

# Dataset para treino
dataset = lgb.Dataset(x_treino,label=y_treino)

# Parâmetros
parametros = {'num_leaves':250, # número de folhas
              'objective':'binary', # classificação Binária     
              'max_depth':2,
              'learning_rate':.05,
              'max_bin':100}

lgbm=lgb.train(parametros,dataset,num_boost_round=200)

# Marcação do tempo de execução
from datetime import datetime
inicio=datetime.now()
lgbm=lgb.train(parametros,dataset)
fim=datetime.now()

tempo = fim - inicio
tempo

previsoes_lgbm = lgbm.predict(x_teste)
previsoes_lgbm

previsoes_lgbm.shape

# Quando for menor que 5 considera 0 e quando for maior ou igual a 5 considera 1
for i in range(0, 634):
    if previsoes_lgbm[i] >= .5:       
       previsoes_lgbm[i] = 1
    else:  
       previsoes_lgbm[i] = 0

previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# Validação Cruzada

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = lgb.LGBMClassifier(num_leaves = 250, objective = 'binary',     
                            max_depth = 2, learning_rate = .05, max_bin =100)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 86,23% - 238 acertos e 85,72% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

KNN = 92,59% - 587 acertos e 90,82% (validação cruzada) :  previsores_esc - KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

Árvore de decisão = 91,80% (treino e teste) - 582 acertos e 90,21% (validação cruzada): previsores_esc - DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

Random Forest = 93,06% - 590 acertos e 90,82% (validação cruzada) : previsores - RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)

XGboost = 95,27% - 604 acertos e 94,75% (validação cruzada) : previsores - XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)

LightGBM = 96,95% (treino e teste)- 615 acertos e 93,47% (validação cruzada) : previsores - lgb.LGBMClassifier(num_leaves = 250, objective = 'binary',  max_depth = 2, learning_rate = .05, max_bin =100)

# Catboost
"""

# **CATBOOST**

#Instalação
!pip install catboost

from catboost import CatBoostClassifier

df

previsores4 = df.iloc[:, 0:21]

previsores4.head()

alvo4 = df.iloc[:, 21]

from sklearn.model_selection import train_test_split

x_treino, x_teste, y_treino, y_teste = train_test_split(previsores4, alvo4, test_size = 0.3, random_state = 0)

catboost = CatBoostClassifier(task_type='CPU', iterations=100, learning_rate=0.1, depth = 8, random_state = 5, 
                              eval_metric="Accuracy")

catboost.fit( x_treino, y_treino, plot=True, eval_set=(x_teste, y_teste))

previsoes_cat = catboost.predict(x_teste)
previsoes_cat

previsoes_cat = catboost.predict(x_teste)
previsoes_cat

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_cat) * 100.0))

confusion_matrix(y_teste, previsoes_cat)

# **Análise dados de treino**
previsoes_treino = catboost.predict(x_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

### **Validação Cruzada**
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = CatBoostClassifier(task_type='CPU', iterations=100, learning_rate=0.1, depth = 8, random_state = 5, 
                              eval_metric="Accuracy")
resultado = cross_val_score(modelo, previsores, alvo, cv = kfold)

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

SVM = 86,23% - 238 acertos e 85,72% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

KNN = 92,59% - 587 acertos e 90,82% (validação cruzada) :  previsores_esc - KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

Árvore de decisão = 91,80% (treino e teste) - 582 acertos e 90,21% (validação cruzada): previsores_esc - DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

Random Forest = 93,06% - 590 acertos e 90,82% (validação cruzada) : previsores - RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)

XGboost = 95,27% - 604 acertos e 94,75% (validação cruzada) : previsores - XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)

LightGBM = 96,95% (treino e teste)- 238 acertos e 85,93% (validação cruzada) : previsores - lgb.LGBMClassifier(num_leaves = 250, objective = 'binary',  max_depth = 2, learning_rate = .05, max_bin =100)

CatBoost = 95,27% (treino e teste) previsores4 - 604 acertos e 94,37% (validação cruzada com previsores) - CatBoostClassifier(task_type='CPU', iterations=100, learning_rate=0.1, depth = 8, random_state = 5, eval_metric="Accuracy")

# AdaBoostClassifier
"""

# AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier

ada = AdaBoostClassifier(n_estimators=1479,random_state=0)

ada.fit(x_treino, y_treino)

# Avaliação do algoritmo
previsoes_ada = ada.predict(x_teste)

previsoes_ada

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

accuracy_score(y_teste, previsoes_ada)

print("Acurácia: %.2f%%" % (accuracy_score(y_teste, previsoes_ada) * 100.0))

confusion_matrix(y_teste, previsoes_ada)

print(classification_report(y_teste, previsoes_ada))

# Análise dados de Treino
previsoes_treino = ada.predict(x_teste)
previsoes_treino

# Validação Cruzada
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo

modelo = AdaBoostClassifier(n_estimators=1479, random_state=0)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)
resultado

# Usamos a média e o desvio padrão
print("Acurácia Média: %.2f%%" % (resultado.mean() * 100.0))

"""# **Avaliação Final**

Naive Bayes = 72,40% (treino e teste) - 459 acertos e 72,50% (validação cruzada)

*SVM *= 86,23% - 238 acertos e 85,72% (validação cruzada) : SVC(kernel='rbf', random_state=1, C = 2)

Regressão logística = 91,01% - 577 acertos e 89,58% (validação cruzada) : previsores_esc - LogisticRegression(random_state=1, max_iter=600, penalty="l2", tol=0.0001, C=1,solver="lbfgs")

KNN = 92,59% - 587 acertos e 90,82% (validação cruzada) : previsores_esc - KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)

Árvore de decisão = 91,80% (treino e teste) - 582 acertos e 90,21% (validação cruzada): previsores_esc - DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)

Random Forest = 93,06% - 590 acertos e 90,82% (validação cruzada) : previsores - RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)

XGboost = 95,27% - 604 acertos e 94,75% (validação cruzada) : previsores - XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)

LightGBM = 96,95% (treino e teste)- 615 acertos e 93,47% (validação cruzada) : previsores - lgb.LGBMClassifier(num_leaves = 250, objective = 'binary', max_depth = 2, learning_rate = .05, max_bin =100)

CatBoost = 95,27% (treino e teste) previsores4 - 604 acertos e 94,37% (validação cruzada com previsores) - CatBoostClassifier(task_type='CPU', iterations=100, learning_rate=0.1, depth = 8, random_state = 5, eval_metric="Accuracy")

AdaBoostClassifier = 91,17% (treino e teste) - 578 acertos e 86,90% (validação cruzada com previsores) - AdaBoostClassifier(n_estimators=1479, random_state=0)

Dentre os modelos avaliados o que teve a melhor porcentagem de acurácia foi o LightGBM com aproximadamente 96,95%. A acurácia é uma métrica utilizada para verificar a performance geral de um modelo, ou seja, das classificações que foram feitas, o quanto o modelo conseguiu classificar corretamente. Nos modelos que avaliamos, o LightGBM teve a melhor performance entre os modelos, tendo 615 acertos. Por outro lado, o Naive Bayes foi o modelo que menos conseguiu classificar corretamente, com uma porcentagem de apenas 72,40%.
"""